{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ffa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import used tools\n",
    "\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data for dim=8\n",
    "# column ‘0’ is the target: robustness of coherence\n",
    "# the rest columns are the matrix elements\n",
    "# the filenames can be renamed in the matlab program which generates the data\n",
    "\n",
    "dataset_path = 'realEntries8.csv'\n",
    "dataset_path_1 = 'realEntries8-1.csv'\n",
    "dataset_path_2 = 'realEntries8-2.csv'\n",
    "dataset_path_3 = 'realEntries8-3.csv'\n",
    "dataset_path_4 = 'realEntries8-4.csv'\n",
    "dataset_path_5 = 'realEntries8-5.csv'\n",
    "dataset_path_6 = 'small_coherence_8.csv'\n",
    "dataset_path_7 = 'realEntriesPure8.csv'\n",
    "\n",
    "\n",
    "\n",
    "column_names=list(range(65)) # coherence + dim * dim\n",
    "column_names = [str(x) for x in column_names]\n",
    "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      skipinitialspace=True)\n",
    "raw_dataset_1 = pd.read_csv(dataset_path_1, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      skipinitialspace=True)\n",
    "raw_dataset_2 = pd.read_csv(dataset_path_2, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      skipinitialspace=True)\n",
    "raw_dataset_3 = pd.read_csv(dataset_path_3, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      skipinitialspace=True)\n",
    "raw_dataset_4 = pd.read_csv(dataset_path_4, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      skipinitialspace=True)\n",
    "raw_dataset_5 = pd.read_csv(dataset_path_5, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      skipinitialspace=True)\n",
    "raw_dataset_6 = pd.read_csv(dataset_path_6, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      skipinitialspace=True)\n",
    "\n",
    "raw_dataset_7 = pd.read_csv(dataset_path_7, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      skipinitialspace=True)\n",
    "\n",
    "\n",
    "raw_dataset = pd.concat([raw_dataset, raw_dataset_1, raw_dataset_2, raw_dataset_3, raw_dataset_4, raw_dataset_5, raw_dataset_6, raw_dataset_7],ignore_index=True)\n",
    "\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "dataset=dataset.sample(frac=1.0).reset_index(drop=True)\n",
    "\n",
    "dataset.head()\n",
    "#dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4738c7-652f-47e4-b5fc-7d3fc2d03206",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae37abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check for bad values in the data and remove those rows.\n",
    "\n",
    "dataset.isna().sum()\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f85c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To split the data into a training set and a test set.\n",
    "\n",
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the size of the data.\n",
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cc310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To inspect the elements of the matrices in the training set.\n",
    "train_stats = train_dataset.describe()\n",
    "train_stats.pop(\"0\")\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To separate the target from the dataset.\n",
    "train_labels = train_dataset.pop('0')\n",
    "test_labels = test_dataset.pop('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908c04c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To normalize the data.\n",
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset).fillna(0)\n",
    "normed_test_data = norm(test_dataset).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the model.\n",
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),    \n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  #optimizer = tf.keras.optimizers.RMSprop(0.01)\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ae030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "    \n",
    "  plt.style.use('seaborn')  \n",
    "    \n",
    "  plt.figure(figsize=(4,3),dpi=120)\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('MAE')\n",
    "  plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error', color='#00468C')\n",
    "  plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label = 'Validation Error', color='#E95C4B')\n",
    "  plt.ylim([0,0.14])\n",
    "  plt.legend()\n",
    "  #plt.grid(True)\n",
    "  plt.savefig('d8MAE.eps',bbox_inches='tight')\n",
    "\n",
    "  plt.figure(figsize=(4,3),dpi=120)\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error')\n",
    "  plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error',color='#00468C')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Val Error',color='#E95C4B')\n",
    "  plt.ylim([0,0.3])\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  #plt.tight_layout()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train the model\n",
    "\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 100 == 0: print('')\n",
    "    print('.', end='')\n",
    "    \n",
    "EPOCHS = 1000\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
    "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b0671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the condition of the test set.\n",
    "\n",
    "\n",
    "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f}\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44a98b-5612-49d5-a421-31f63a45f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the performance of prediction\n",
    "\n",
    "\n",
    "test_predictions = model.predict(normed_test_data).flatten()\n",
    "\n",
    "\n",
    "r2 = round(1 - sum((test_labels - test_predictions) ** 2)/sum((test_labels - np.mean(test_labels)) ** 2),4)\n",
    "\n",
    "plt.figure(figsize=(4,4),dpi=120)\n",
    "plt.style.use('classic')\n",
    "plt.text(1.5,0.75, \"d = 4\",fontsize=16, fontweight='bold',fontfamily='Times New Roman')\n",
    "plt.text(1.5,0.5,\"R$^2$ = \" + str(r2) + \"\",fontsize=16, fontweight='bold',fontfamily='Times New Roman')\n",
    "plt.scatter(test_labels[:1000], test_predictions[:1000],\n",
    "            s=20,c='none',edgecolor=(20/255,81/255,124/255),marker=\"o\",alpha=1,linewidth=0.3)\n",
    "plt.xlabel('Actual ROC')\n",
    "plt.ylabel('Predicted ROC')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([-0.,4.])\n",
    "plt.ylim([-0.,4.])\n",
    "plt.plot([0, 10.05], [0, 10],c='r',lw=1.5,alpha=1)\n",
    "plt.xticks(fontsize=12, fontname='Times New Roman') \n",
    "plt.yticks(fontsize=12, fontname='Times New Roman')  \n",
    "\n",
    "\n",
    "plt.savefig('d8.eps',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c40494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "model.save('d8.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebd167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "model = tf.keras.models.load_model('d8.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b462842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
