{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72d34b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import used tools\n",
    "\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from scipy import stats\n",
    "\n",
    "import time\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c030ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data for dim=6\n",
    "# column ‘0’ is the target: robustness of coherence\n",
    "# the rest columns are the matrix elements\n",
    "# the filenames can be renamed in the matlab program which generates the data\n",
    "\n",
    "dataset_path = 'yXcoherence6dmixed.csv'\n",
    "dataset_path_1 = 'yXcoherence6dmixed_1.csv'\n",
    "dataset_nonmarkov = 'yXcoherence6dmixed_2.csv'\n",
    "dataset_nonmarkov1 = 'yXcoherence6_3dmixed.csv'\n",
    "dataset_nonmarkov2 = 'yXcoherence6_4dmixed.csv'\n",
    "dataset_nonmarkov3 = 'yXcoherence6_5dmixed.csv'\n",
    "dataset_path_pure = 'yXcoherence6dpure.csv'\n",
    "\n",
    "\n",
    "column_names=list(range(37))\n",
    "column_names = [str(x) for x in column_names]\n",
    "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      skipinitialspace=True)\n",
    "raw_dataset_1 = pd.read_csv(dataset_path_1, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      skipinitialspace=True)\n",
    "raw_dataset_pure = pd.read_csv(dataset_path_pure, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                     skipinitialspace=True)\n",
    "\n",
    "raw_nonmarkov = pd.read_csv(dataset_nonmarkov, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                     skipinitialspace=True)\n",
    "raw_nonmarkov1 = pd.read_csv(dataset_nonmarkov1, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                     skipinitialspace=True)\n",
    "raw_nonmarkov2 = pd.read_csv(dataset_nonmarkov2, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                     skipinitialspace=True)\n",
    "raw_nonmarkov3 = pd.read_csv(dataset_nonmarkov3, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                     skipinitialspace=True)\n",
    "\n",
    "raw_dataset = pd.concat([raw_dataset, raw_dataset_1, raw_nonmarkov, raw_nonmarkov1,raw_nonmarkov2,raw_nonmarkov3, raw_dataset_pure],ignore_index=True) #合并多个，重新排列index\n",
    "\n",
    "\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.head()\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check for bad values in the data and remove those rows.\n",
    "\n",
    "dataset.isna().sum()\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To split the data into a training set and a test set.\n",
    "\n",
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac4e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the size of the data.\n",
    "test_dataset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To inspect the elements of the matrices in the training set.\n",
    "train_stats = train_dataset.describe()\n",
    "train_stats.pop(\"0\")\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To separate the target from the dataset.\n",
    "train_labels = train_dataset.pop('0')\n",
    "test_labels = test_dataset.pop('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc7fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To normalize the data.\n",
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset).fillna(0)\n",
    "normed_test_data = norm(test_dataset).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7747120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To build the model.\n",
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "    layers.Dense(64, activation='relu'),  \n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  #optimizer = tf.keras.optimizers.RMSprop(0.0001)\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774df4c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  hist['epoch'] = history.epoch\n",
    "  plt.figure(figsize=(4,3),dpi=120)\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('MAE')\n",
    "  plt.xticks(fontsize=12, fontname='Times New Roman')  \n",
    "  plt.yticks(fontsize=12, fontname='Times New Roman')  \n",
    "  plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error',color=(20/255,81/255,124/255),linestyle='--')\n",
    "  plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label = 'Validation Error',color=(200/255,36/255,35/255))\n",
    "  plt.ylim([0.0,0.08])\n",
    "  plt.legend()\n",
    "  plt.savefig('d6MAE.eps',bbox_inches='tight')\n",
    " \n",
    "    \n",
    " \n",
    "  plt.figure(figsize=(4,3),dpi=120)\n",
    "\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('MSE')\n",
    "  \n",
    "\n",
    "  plt.xticks(fontsize=12, fontname='Times New Roman')  \n",
    "  plt.yticks(fontsize=12, fontname='Times New Roman')  \n",
    "  plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error',color=(20/255,81/255,124/255),linestyle='--')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Validation Error',color=(200/255,36/255,35/255))\n",
    "  plt.xlim([0,40])\n",
    "  plt.ylim([0.000,0.012])\n",
    "\n",
    "  plt.legend()\n",
    "  \n",
    "  \n",
    "  plt.savefig('d6MSE.eps',bbox_inches='tight')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c23b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train the model\n",
    "\n",
    "\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 100 == 0: print('')\n",
    "    print('.', end='')\n",
    "    \n",
    "EPOCHS = 1000\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
    "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4d66df-edea-405d-b314-39ca054bc6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the condition of the test set.\n",
    "\n",
    "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f}\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the performance of prediction\n",
    "\n",
    "\n",
    "test_predictions = model.predict(normed_test_data).flatten()\n",
    "\n",
    "r2 = round(1 - sum((test_labels - test_predictions) ** 2)/sum((test_labels - np.mean(test_labels)) ** 2),4)\n",
    "\n",
    "plt.figure(figsize=(8,4),dpi=120)\n",
    "plt.style.use('classic')\n",
    "\n",
    "plt.text(1.75,1.05, \"d = 6\")\n",
    "plt.text(1.75,0.7,\"R$^2$ = \" + str(r2) + \"\")\n",
    "\n",
    "\n",
    "plt.scatter(test_labels[:2000], test_predictions[:2000],s=20,c='none',edgecolor=(20/255,81/255,124/255),marker=\"o\",alpha=1,linewidth=0.3)\n",
    "\n",
    "plt.xlabel('Actual ROC')\n",
    "plt.ylabel('Predicted ROC')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,3.5])\n",
    "plt.ylim([0,3.5])\n",
    "plt.xticks(fontsize=12, fontname='Times New Roman')  \n",
    "plt.yticks(fontsize=12, fontname='Times New Roman') \n",
    "\n",
    "\n",
    "\n",
    "plt.plot([0, 10.05], [0, 10],c=(200/255,36/255,35/255),lw=1.5,alpha=1)\n",
    "\n",
    "\n",
    "plt.savefig('d6.eps',bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fd20d-1f56-44a5-9654-5fc9a327f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "model.save('d6.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd694ac-af2c-4ee7-b077-fc4015db2259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "new_model = tf.keras.models.load_model('d6.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
